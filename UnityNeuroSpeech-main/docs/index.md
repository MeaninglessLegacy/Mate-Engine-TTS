<div style="text-align: center;">
<img src="media/logo.png">
</div>

#

> **Make your Unity characters hear, think, and talk â€” using real voice AI. Locally. No cloud.**

---

UnityNeuroSpeech is a lightweight and open-source framework for creating **fully voice-interactive AI agents** inside Unity.  
It connects:

- ğŸ§  **Whisper** (STT) â€“ converts your speech into text  
- ğŸ’¬ **Ollama** (LLM) â€“ generates smart responses  
- ğŸ—£ï¸ **XTTS** (TTS) â€“ speaks back with *custom voice + emotions*

All locally. All offline.  
No subscriptions, no accounts, no OpenAI API keys.

---

## ğŸš€ What can you build with UnityNeuroSpeech?

- ğŸ® AI characters that understand your voice and reply in real time  
- ğŸ—¿ NPCs with personality and memory  
- ğŸ§ª Experiments in AI conversation and narrative design  
- ğŸ•¹ï¸ Voice-driven gameplay mechanics  
- ğŸ¤– Interactive bots with humanlike voice responses

---

## âœ¨ Core Features

| Feature | Description                                                                                |
|--------|--------------------------------------------------------------------------------------------|
| ğŸ™ï¸ **Voice Input** | Uses [whisper.unity](https://github.com/Macoron/whisper.unity) for accurate speech-to-text |
| ğŸ§  **AI Brain (LLM)** | Easily connect to any local model via [Ollama](https://ollama.com)                         |
| ğŸ—£ï¸ **Custom TTS** | Supports any voice with [Coqui XTTS](https://github.com/coqui-ai/TTS)                      |
| ğŸ˜„ **Emotions** | Emotion tags (`<happy>`, `<sad>`, etc.) parsed automatically from LLM                      |
| ğŸ›ï¸ **Agent API** | Subscribe to events like `BeforeTTS()` or access `AgentState` directly                     |
| ğŸ› ï¸ **Editor Tools** | Create, manage and customize agents inside Unity Editor                                    |
| ğŸ§± **No cloud** | All models and voice run locally on your machine                                           |
| ğŸŒ **Multilingual** | Works with over **15+ languages**, including English, Russian, Chinese, etc.               |

---

## ğŸ§ª Built with:

- ğŸ§  [`Microsoft.Extensions.AI`](https://learn.microsoft.com/en-us/dotnet/ai/) (Ollama)
- ğŸ¤ [`whisper.unity`](https://github.com/Macoron/whisper.unity)
- ğŸ [Python Flask server](other/server.md) (for TTS)
- ğŸ§Š [Coqui XTTS model](https://github.com/coqui-ai/TTS)
- ğŸ¤– Unity 6

---

## ğŸ“š Get Started

- ğŸ [Quick Start](quickstart.md)
- âš™ï¸ [Configure Settings](unity/configure-settings.md)
- ğŸ§  [Create Agent](unity/creating-agent.md)
- ğŸ”Œ [Agent API](unity/agent-api.md)
- ğŸ”Š [Build Your Game](unity/building-game.md)
- ğŸ [About Python Server](other/server.md)
- â“ [FAQ](other/faq.md)

---

## ğŸ˜ Who made this?

UnityNeuroSpeech was created by [HardCodeDev](https://github.com/HardCodeDev777) â€”  
indie dev from Russia who just wanted to make AI talk in Unity.

---

## â­ Star it on GitHub  
[ğŸ‘‰ github.com/HardCodeDev777/UnityNeuroSpeech](https://github.com/HardCodeDev777/UnityNeuroSpeech)
